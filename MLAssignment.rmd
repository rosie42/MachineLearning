---
title: "Machine Learning Assignment"
author: "Michael Rose"
date: "Sunday, September 27, 2015"
output: html_document
---

## Data Preparation
First we load the caret library and set the seed for reproducibility.

```{r}
library(caret)

set.seed(3141)
```

We then read the training and submission set into memory and set the training class `classe` as a factor for classification.  We set the submission set aside so as not to bias our analysis and training.

```{r}
baseTrain <- read.csv("pml-training.csv", stringsAsFactors = FALSE)
submissionSet <- read.csv("pml-testing.csv", stringsAsFactors = FALSE)

baseTrain$classe <- factor(baseTrain$classe)
```


A review of the training data shows many of the variables are not populated or very sparsely populated.  It is of little value including these mostly empty variables and likely to introduce errors as we examine different models.  Therefore, we will only include the well populated variables in our training set.  We also exclude the initial columns containing index and timestamp information as this is not relavent to the quality of the lift.

```{r}
#variable X and timestamps should be removed from analysis as irrelevant to classification
baseTrain <- baseTrain[-c(1:7)]

fullTrain <- baseTrain[c("roll_belt", "pitch_belt", "yaw_belt", "total_accel_belt",
 "gyros_belt_x", "gyros_belt_y", 
 "gyros_belt_z", "accel_belt_x", "accel_belt_y", "accel_belt_z", 
 "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "roll_arm", 
 "pitch_arm", "yaw_arm", "total_accel_arm", 
 "gyros_arm_x", "gyros_arm_y", "gyros_arm_z",
 "accel_arm_x", "accel_arm_y", "accel_arm_z", "magnet_arm_x",
 "magnet_arm_y", "magnet_arm_z",
 "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell", 
 "total_accel_dumbbell",
 "gyros_dumbbell_x", "gyros_dumbbell_y", 
 "gyros_dumbbell_z", "accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", 
 "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z", "roll_forearm", 
 "pitch_forearm", "yaw_forearm", "total_accel_forearm", 
 "gyros_forearm_x", 
 "gyros_forearm_y", "gyros_forearm_z", "accel_forearm_x", "accel_forearm_y", 
 "accel_forearm_z", "magnet_forearm_x", "magnet_forearm_y", "magnet_forearm_z", "classe")]
```

We now partition the training set into a proper training and test set for analysis
``` {r}
inTrain <- createDataPartition(fullTrain$classe, p = 0.7, list = FALSE)

train <- fullTrain[inTrain,]
test <- fullTrain[-inTrain,]
```


# Principal Components Analysis

Given that we have many numeric variables, it is reasonable to perform a Principal Component analysis to see if we can reduce the dimensionality of the training.  This will allow us to use more complex modelling techniques without impacting training time signifcantly.

We see that we can find a set of vectors explaining much of the variability with less than half the dimension of the initial training set.
```{r}
trainPC <- preProcess(train[-c(53)], method ="pca", thresh = 0.9) 

trainPC
```

## Model Fitting
First we fit a basic decision tree and see that the results are not outstanding.  
```{r}
train(train$classe ~ ., data = predict(trainPC, train[-c(53)]), method = "rpart")
```

Since we performed a PCA above, our dimensionality is such that a random forest can be fit in a reasonable amount of time.  We see below that the performance is promising.
```{r, cache=TRUE}
forestModel <- train(train$classe ~ ., data = predict(trainPC, train[-c(53)]), method = "rf")

forestModel
```

In general, random forests are self-validating, but we have our test set available and it is wise to double check performance. We predict the labels for our test set using our random forest model and measure the accuracy below.

```{r, cache=TRUE}
# validate model against test set
testPC <- predict(trainPC, test[-c(53)])
predictions <- predict(forestModel, newdata = testPC)

# test set accuracy
accuracy <- sum(test$classe==predictions)/length(predictions)
```

We see similar performance in our test set as in our training set as expected.  And thus expect a `r 1-accuracy` misclassification rate.

## Submission
We extract the relevant variables from the submission set, apply the Pricipal Components transformation from the training set and predict the class labels using the random forest model.

```{r, cache=TRUE}
# prepare the submission set
submitPC <- predict(trainPC, submissionSet[c("roll_belt", "pitch_belt", "yaw_belt", "total_accel_belt",
 "gyros_belt_x", "gyros_belt_y", 
 "gyros_belt_z", "accel_belt_x", "accel_belt_y", "accel_belt_z", 
 "magnet_belt_x", "magnet_belt_y", "magnet_belt_z", "roll_arm", 
 "pitch_arm", "yaw_arm", "total_accel_arm", 
 "gyros_arm_x", "gyros_arm_y", "gyros_arm_z",
 "accel_arm_x", "accel_arm_y", "accel_arm_z", "magnet_arm_x",
 "magnet_arm_y", "magnet_arm_z",
 "roll_dumbbell", "pitch_dumbbell", "yaw_dumbbell", 
 "total_accel_dumbbell",
 "gyros_dumbbell_x", "gyros_dumbbell_y", 
 "gyros_dumbbell_z", "accel_dumbbell_x", "accel_dumbbell_y", "accel_dumbbell_z", 
 "magnet_dumbbell_x", "magnet_dumbbell_y", "magnet_dumbbell_z", "roll_forearm", 
 "pitch_forearm", "yaw_forearm", "total_accel_forearm", 
 "gyros_forearm_x", 
 "gyros_forearm_y", "gyros_forearm_z", "accel_forearm_x", "accel_forearm_y", 
 "accel_forearm_z", "magnet_forearm_x", "magnet_forearm_y", "magnet_forearm_z")])

submissionPredictions <- predict(forestModel, newdata = submitPC)
```

We now load the submission code from the assignment into memory and write our predicitions to file for submission.

```{r, eval = FALSE}
#write out predictions for submissionSet

pml_write_files = function(x){
  n = length(x)
  for(i in 1:n){
    filename = paste0("problem_id_",i,".txt")
    write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
  }
}

setwd("./submit")
pml_write_files(submissionPredictions)
setwd("../")
```
